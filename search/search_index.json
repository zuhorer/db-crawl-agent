{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<ul> <li>llm integration </li> <li> <p>llm provider api, </p> </li> <li> <p>runnable llm adapter</p> </li> <li>runnable chat model</li> <li>chat_openai</li> <li></li> </ul> <p>right now my tool call integration is with openai llms which wraps </p>"},{"location":"guides/open_ai_chat_model_integration/","title":"Openai integration","text":"<p>OpenAI Chat Model Integration</p> <p>This module provides the OpenAI chat model integration for db-crawl. It acts as a thin adapter layer between db-crawl\u2019s internal message / tool formats and the OpenAI Chat Completions API.</p> <p>The implementation intentionally keeps OpenAI-specific logic isolated so the rest of the system remains provider-agnostic.</p> <p>Responsibilities</p> <p>The OpenAI integration is responsible for:     1.  Converting db-crawl messages into OpenAI-compatible messages     2.  Sending chat completion requests to OpenAI     3.  Converting OpenAI tool calls back into db-crawl\u2019s internal format</p> <p>It does not:     \u2022   Define tools     \u2022   Execute tools     \u2022   Manage agent state or control flow     \u2022   Store conversation history outside the current request</p> <p>Message Conversion</p> <p>_convert_messages(db_crawl_messages)</p> <p>Converts db-crawl\u2019s internal message objects into the OpenAI messages format.</p> <p>Purpose OpenAI expects messages in a strict role-based schema. db-crawl uses its own internal message abstractions. This function bridges the two.</p> <p>Behavior     \u2022   Maps db-crawl message roles to OpenAI roles:     \u2022   system \u2192 role=\"system\"     \u2022   user \u2192 role=\"user\"     \u2022   assistant \u2192 role=\"assistant\"     \u2022   tool \u2192 role=\"tool\"     \u2022   Preserves message ordering     \u2022   Passes message content verbatim     \u2022   Includes tool_call_id for tool messages when present</p> <p>Output Returns a list of OpenAI-compatible message dictionaries suitable for the messages field in a chat completion request.</p> <p>Tool Call Conversion</p> <p>_convert_tool_calls(openai_response)</p> <p>Converts tool calls returned by OpenAI into db-crawl\u2019s internal tool-call representation.</p> <p>Purpose OpenAI returns tool calls in its own schema, with arguments encoded as JSON strings. db-crawl expects structured tool calls with parsed arguments.</p> <p>Behavior For each OpenAI tool call:     \u2022   Extracts the tool call ID     \u2022   Extracts the tool name     \u2022   Parses the JSON argument string into a Python dictionary     \u2022   Emits a db-crawl tool-call object in the expected internal format</p> <p>Notes     \u2022   Tool call IDs are preserved so tool results can be correlated correctly     \u2022   Argument parsing errors are surfaced to the caller</p> <p>Chat Completion Execution</p> <p>The OpenAI integration sends a chat completion request using:     \u2022   Converted messages from _convert_messages     \u2022   Model configuration supplied to the class     \u2022   Tool definitions supplied by the caller</p> <p>The raw OpenAI response is then inspected for tool calls, which are converted using _convert_tool_calls.</p> <p>This module does not decide when tools are executed or how results are fed back. It only translates formats.</p> <p>Design Constraints     \u2022   No OpenAI types leak outside the adapter     \u2022   No db-crawl internal types leak into the OpenAI request     \u2022   All provider-specific logic is centralized in this module     \u2022   Other model providers must be able to implement the same interface</p> <p>\u2e3b</p> <p>Summary</p> <p>The OpenAI chat integration is a format adapter with three core concerns:     \u2022   Input: db-crawl messages \u2192 OpenAI messages     \u2022   Execution: OpenAI chat completion call     \u2022   Output: OpenAI tool calls \u2192 db-crawl tool calls</p> <p>Nothing more, nothing less.</p>"}]}